Para dimensionar el fenómeno, pensemos en el GPT-3, el antecesor de ChatGPT, cuyo entrenamiento en 2020 implicó un costo aproximado de 4,6 millones de dólares solo en energía para procesar los datos. Esto requiere centros de datos especializados con GPUs y TPUs, tecnologías esenciales para estas tareas. El potencial de hablar sobre estas tecnologías y sus implicancias es grande, dado que marcan la diferencia en la capacidad de procesamiento de estos modelos.

Con GPT-3 se evidenció que el volumen de datos traduce calidad, situándolo como un salto evolutivo frente a sus predecesores. Posteriormente, surgieron modelos como Codex, integrado en herramientas como GitHub Copilot, y ChatGPT, diseñado para interactuar en formatos de conversación. Este último, a diferencia del GPT-3 que funciona como API, está entrenado para simular un diálogo.

La proliferación de modelos por parte de grandes empresas como OpenAI, Meta y Google, y la tendencia a apartarse del software libre, nos lleva a reflexionar sobre las consecuencias de esta elección. El software libre permite una amplia colaboración y mejora continua, algo que ha sido fundamental para el desarrollo de internet y tecnologías subyacentes. Este espíritu de colaboración está en el ADN de las grandes innovaciones tecnológicas y es una práctica habitual incluso en empresas que luego optan por modelos de negocio basados en software propietario.

La transparencia de los Large Language Models (LLMs) es crucial. Hay modelos básicos que se limitan a predecir la próxima palabra basándose en datos previos, y luego están los avanzados por el RLHF (Reinforcement Learning from Human Feedback), que permiten que los modelos, sin algoritmos específicos para tareas concretas, sigan instrucciones como si estuvieran programados para ello, un avance que nos asombra por su aparente "magia".

El caso de Alpaca de Stanford es particularmente notable. Tras la filtración de un modelo de Meta, estudiantes de Stanford refinaron un modelo usando recursos limitados y lo compartieron con licencias que restringen el uso comercial, impulsando experimentos en la comunidad open source. Esto demuestra la agilidad y el potencial disruptivo del software libre frente a los modelos cerrados.

Un informe filtrado de Google sugiere que la hegemonía en este campo podría ser desafiada por la comunidad open source, que ya está logrando resultados impresionantes en modelos más pequeños. Los usuarios deciden el tipo de retroalimentación que estos modelos reciben, personalizando así sus capacidades y comportamientos.

En resumen, mientras que la inteligencia artificial transforma nuestra interacción con el contenido digital, es fundamental avanzar con plena conciencia del poder y los riesgos que conllevan. Estas herramientas, aunque parezcan mágicas, no comprenden ni son conscientes, y debemos proceder con precaución mientras continuamos explorando sus asombrosas capacidades.