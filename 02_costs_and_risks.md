To gauge the magnitude of the phenomenon, consider GPT-3, ChatGPT's predecessor, whose 2020 training carried an approximate cost of $4.6 million in energy alone to process the data. This requires specialized data centers with GPUs and TPUs, technologies essential for these tasks. The potential to discuss these technologies and their implications is significant, as they make the difference in these models' processing capabilities. With GPT-3 it became evident that data volume translates to quality, positioning it as an evolutionary leap from its predecessors. Afterwards, models like Codex emerged, integrated into tools like GitHub Copilot, and ChatGPT, designed to interact in conversational formats. The latter, unlike GPT-3 which functions as an API, is trained to simulate a dialogue. The proliferation of models from large companies like OpenAI, Meta, and Google, and the tendency to move away from open source, leads us to reflect on the consequences of this choice. Open source software enables broad collaboration and continuous improvement, something that has been fundamental to the development of the internet and underlying technologies. This spirit of collaboration is in the DNA of major technological innovations and is common practice even in companies that later opt for proprietary business models. The transparency of Large Language Models (LLMs) is crucial. There are basic models that simply predict the next word based on previous data, and then there are the advanced ones through RLHF (Reinforcement Learning from Human Feedback), which allow models, without specific algorithms for concrete tasks, to follow instructions as if they were programmed to do so, an advance that astonishes us for its apparent "magic." The case of Alpaca from Stanford is particularly remarkable. After a Meta model leaked, Stanford students refined a model using limited resources and shared it with licenses restricting commercial use, propelling experiments in the open source community. This demonstrates the agility and disruptive potential of open source compared to closed models. A leaked Google report suggests that open source community could challenge this field's hegemony, already achieving impressive results on smaller models. Users decide the type of feedback these models receive, thus personalizing their capabilities and behaviors. In summary, while artificial intelligence transforms our interaction with digital content, it is essential to advance with full awareness of the power and risks they entail. These tools, although seemingly magical, neither understand nor are conscious, and we must proceed cautiously as we continue exploring their astonishing capabilities.